{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33366d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(str(Path.cwd() / \"src\"))\n",
    "\n",
    "from sleepiness import SleepinessData\n",
    "\n",
    "file_paths = [\n",
    "    \"sleep-data/phase-1-1/data-streams.json\",\n",
    "    \"sleep-data/phase-2-1/data-streams.json\",\n",
    "    \"sleep-data/phase-3-1/data-streams.json\"\n",
    "]\n",
    "# OR\n",
    "# file_paths = \"data/phase-1-1/data-streams.json\"\n",
    "\n",
    "sd = SleepinessData(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc794a",
   "metadata": {},
   "source": [
    "## Participant Data Integration\n",
    "When loading multiple data folders, the library automatically loads `participant-data.json` from each folder and unifies participants across folders (using email/SSN as identifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e00b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all participants across all loaded data folders\n",
    "sd.print_participants()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c2bed",
   "metadata": {},
   "source": [
    "### Data with Participant Info\n",
    "Iterate through data items enriched with participant information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35b3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get participant info for a specific deployment\n",
    "# for item in sd._get_item_generator():\n",
    "#     deployment_id = item.get('studyDeploymentId')\n",
    "#     if deployment_id:\n",
    "#         participant = sd.get_participant(deployment_id)\n",
    "#         if participant:\n",
    "#             print(f\"Deployment: {deployment_id[:30]}...\")\n",
    "#             print(f\"  Unified ID: {participant.unified_participant_id}\")\n",
    "#             print(f\"  Email: {participant.email}\")\n",
    "#             print(f\"  Source folder: {participant.source_folder}\")\n",
    "#         break\n",
    "\n",
    "# Get participant info\n",
    "sd.participant(\"test@example.com\").info()\n",
    "sd.participant(\"test@example.com\").print_info()\n",
    "\n",
    "# Get all data for this participant\n",
    "count = 0\n",
    "for item in sd.participant(\"test@example.com\").all_data():\n",
    "    print(item)\n",
    "    count += 1\n",
    "    if count >= 5:\n",
    "        print(\"Limit output for demo\")\n",
    "        break\n",
    "\n",
    "# Filter by data type\n",
    "for item in sd.participant(\"test@example.com\").all_data(\"dk.cachet.carp.location\"):\n",
    "    print(item)\n",
    "\n",
    "# See available fields\n",
    "sd.participant(\"test@example.com\").available_fields()\n",
    "sd.participant(\"test@example.com\").print_available_fields()\n",
    "\n",
    "# See data types available\n",
    "sd.participant(\"test@example.com\").data_types()\n",
    "sd.participant(\"test@example.com\").print_data_types()\n",
    "\n",
    "# Get count\n",
    "sd.participant(\"test@example.com\").count()\n",
    "\n",
    "# Get DataFrame\n",
    "df = sd.participant(\"test@example.com\").dataframe(\"dk.cachet.carp.stepcount\")\n",
    "\n",
    "# Check if exists\n",
    "sd.participant(\"test@example.com\").exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6145e273",
   "metadata": {},
   "source": [
    "### DataFrame with Participant Info\n",
    "Get a DataFrame enriched with participant columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507cb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame with participant columns\n",
    "df = sd.get_dataframe_with_participants(\"dk.cachet.carp.stepcount\")\n",
    "if df is not None and not df.empty:\n",
    "    print(df[['participant_id', 'participant_email', 'participant_folder']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158d50b",
   "metadata": {},
   "source": [
    "### Visualize Participant Data on Map\n",
    "Generate a heatmap aggregating data for a specific participant across all their deployments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761607c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sleepiness.plotting import LocationVisualizer\n",
    "\n",
    "# Create visualizer\n",
    "viz = LocationVisualizer(sd)\n",
    "\n",
    "# Plot heatmap for a specific participant (e.g., P0002 who appears in all 3 phases)\n",
    "viz.plot_participant_heatmap(\n",
    "    unified_participant_id=\"P0002\",  # Choose a participant from the summary table\n",
    "    output_file=\"participant_heatmap.html\",\n",
    "    location_type=\"dk.cachet.carp.location\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9477bd0",
   "metadata": {},
   "source": [
    "## 1. Schema Discovery\n",
    "Scan the file to understand the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.print_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f655a6",
   "metadata": {},
   "source": [
    "### Generate Type Definitions\n",
    "You can generate a Python module with dataclasses representing the data schema. This allows for type-safe access to the data, including nested JSON objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sleepiness.reader\n",
    "importlib.reload(sleepiness.reader)\n",
    "\n",
    "# Re-initialize sd to ensure latest code is used\n",
    "sd = sleepiness.reader.SleepinessData(file_paths)\n",
    "sd.generate_type_definitions(output_file=\"generated_types.py\", sample_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of generated types\n",
    "try:\n",
    "    import generated_types\n",
    "    import importlib\n",
    "    importlib.reload(generated_types)\n",
    "    \n",
    "    # Read one item and convert\n",
    "    gen = sd._get_item_generator()\n",
    "    item = next(gen)\n",
    "    \n",
    "    obj = generated_types.SleepinessItem.from_dict(item)\n",
    "    print(f\"Converted object type: {type(obj)}\")\n",
    "    if obj.dataStream and obj.dataStream.dataType:\n",
    "        print(f\"Data Stream: {obj.dataStream.dataType.name}\")\n",
    "except ImportError:\n",
    "    print(\"Could not import generated_types. Please restart kernel or check file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = next(sd._get_item_generator())\n",
    "obj = generated_types.SleepinessItem.from_dict(item)\n",
    "sd.generate_type_definitions(output_file=\"generated_types.py\", sample_size=500)\n",
    "\n",
    "item = next(sd._get_item_generator())\n",
    "obj = generated_types.SleepinessItem.from_dict(item)\n",
    "\n",
    "# Type-safe access\n",
    "print(obj.dataStream.dataType.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243a62f",
   "metadata": {},
   "source": [
    "## 2. Count Items\n",
    "Count the total number of records in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814969c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = sd.count_items()\n",
    "print(f\"Total items: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f357eba",
   "metadata": {},
   "source": [
    "## 3. Grouping Data\n",
    "Split the large JSON file into smaller files based on the data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e151d64",
   "metadata": {},
   "source": [
    "### Explore Available Fields\n",
    "You can scan a sample of the data to list all available fields in dot-notation. This is helpful for deciding which field to group by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3c6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = sd.list_all_fields(sample_size=500)\n",
    "print(\"Available fields for grouping:\")\n",
    "for f in fields:\n",
    "    print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_groups = \"output_groups\"\n",
    "# sd.group_by_field(\"dataStream.studyDeploymentId\", output_groups)\n",
    "sd.group_by_email(output_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f3497",
   "metadata": {},
   "source": [
    "## 4. Export to JSON\n",
    "Export a specific data type to a separate JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9aa571",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.export_to_json(\"heartbeat.json\", data_type=\"dk.cachet.carp.heartbeat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c9eb8",
   "metadata": {},
   "source": [
    "## 5. Convert to Parquet\n",
    "Convert the data to Parquet format for efficient storage and loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a648c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_dir = \"output_parquet\"\n",
    "sd.convert_to_parquet(parquet_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f02117",
   "metadata": {},
   "source": [
    "## 6. Load DataFrame\n",
    "Load data into a pandas DataFrame, utilizing the Parquet files if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9112e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stepcount data\n",
    "df = sd.get_dataframe(\"dk.cachet.carp.completedtask\", parquet_dir)\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df first row\n",
    "df.iloc[313].measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10095ea",
   "metadata": {},
   "source": [
    "## 7. Plotting\n",
    "Generate a heatmap of user locations and overlay step count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sleepiness.plotting import LocationVisualizer\n",
    "\n",
    "# Initialize visualizer\n",
    "viz = LocationVisualizer(sd)\n",
    "\n",
    "# Pick a user ID (you can find one from the grouping step or list_all_fields)\n",
    "# For demo purposes, let's try to find a valid ID from the loaded dataframe if available, \n",
    "# or just use a hardcoded one if you know it.\n",
    "study_deployment_id = \"0efd5a7f-6428-48db-8099-8d65a62606b4\" # Example ID\n",
    "\n",
    "# Generate heatmap\n",
    "# Note: Ensure you have 'dk.cachet.carp.geolocation' and 'dk.cachet.carp.stepcount' data available\n",
    "# You might need to run convert_to_parquet first if you haven't.\n",
    "\n",
    "\n",
    "viz.plot_user_heatmap(\n",
    "    study_deployment_id=study_deployment_id,\n",
    "    location_type=\"dk.cachet.carp.location\", # Adjust type name if different\n",
    "    step_type=\"dk.cachet.carp.stepcount\",       # Adjust type name if different\n",
    "    output_file=\"user_heatmap.html\"\n",
    ")\n",
    "\n",
    "# Display the map in the notebook\n",
    "# from IPython.display import IFrame\n",
    "# IFrame(src='user_heatmap.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63223a42",
   "metadata": {},
   "source": [
    "### Plotting with Type-Safe Objects\n",
    "You can also convert the data to type-safe objects and pass them directly to the visualizer. This is useful if you want to manipulate the objects before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997894b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get DataFrames\n",
    "df_loc = sd.get_dataframe(\"dk.cachet.carp.location\", parquet_dir)\n",
    "df_steps = sd.get_dataframe(\"dk.cachet.carp.stepcount\", parquet_dir)\n",
    "\n",
    "# 2. Filter by User\n",
    "# Using the same ID as above\n",
    "if df_loc is not None and not df_loc.empty:\n",
    "    df_loc_user = df_loc[df_loc['studyDeploymentId'] == study_deployment_id]\n",
    "    df_steps_user = df_steps[df_steps['studyDeploymentId'] == study_deployment_id] if df_steps is not None else pd.DataFrame()\n",
    "\n",
    "    # 3. Convert to Objects\n",
    "    # Note: generated_types.SleepinessItem.from_dict expects a dictionary structure matching the JSON.\n",
    "    # If df_loc comes from Parquet, it might have nested columns as dicts (if read correctly) or flat columns.\n",
    "    # Let's assume it has nested columns or we convert it.\n",
    "    \n",
    "    # If the dataframe has nested dicts (e.g. 'measurement' column contains dicts):\n",
    "    location_items = [generated_types.SleepinessItem.from_dict(row) for row in df_loc_user.to_dict('records')]\n",
    "    step_items = [generated_types.SleepinessItem.from_dict(row) for row in df_steps_user.to_dict('records')]\n",
    "    \n",
    "    print(f\"Converted {len(location_items)} location items and {len(step_items)} step items.\")\n",
    "\n",
    "    # 4. Plot\n",
    "    viz.plot_heatmap_from_items(\n",
    "        location_items=location_items,\n",
    "        step_items=step_items,\n",
    "        output_file=\"user_heatmap_objects.html\"\n",
    "    )\n",
    "    \n",
    "    # Display\n",
    "    # IFrame(src='user_heatmap_objects.html', width=700, height=600)\n",
    "else:\n",
    "    print(\"No data found to plot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carp-analytics-python (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
